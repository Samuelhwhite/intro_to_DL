{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NNs and CNNs - Complete","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM7gG4NQTsHMxUbY7iRuIDZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TYtwAav8vtqg","colab_type":"text"},"source":["# Building a NN\n","\n","Welcome to building NNs for hand-written digit classification. In this workbook we'll take you through the main steps of building a decent categorisation algorithm for digits 0-9:\n","\n","\n","1.   Setting up the workbook for MAXIMUM SPEED\n","2.   Loading the required modules for the workbook to work\n","3.   Loading the data and analysing the data \n","4.   Pre-processing the data - **honestly, this is the dull bit**\n","5.   Defining a model\n","6.   Training a model\n","7.   Testing the model\n","\n","And then we're going to do it all over again for CNNs!"]},{"cell_type":"markdown","metadata":{"id":"mna10cRBwpBS","colab_type":"text"},"source":["### 1. MAXIMUM SPEED\n","\n","Google Colab generously gives you one GPU (graphics processing unit) to run computations on.\n","A GPU is much quicker than a CPU, in that it can perform many more FLOPs (floating point operations [read \"calculations\"]) per second.\n","\n","To turn this feature on go to:\n","Edit > Notebook Settings > Change the hardware accelerator to GPU\n"]},{"cell_type":"code","metadata":{"id":"MfTo4Ir6viY6","colab_type":"code","colab":{}},"source":["# If this code runs and says \"Found GPU ...\" etc then congrats, you've turned the computation machine to full volume\n","\n","import tensorflow as tf # Importing our first module (as below) but we need it \n","                        # earlier to check whether we have the GPU running in the correct place!\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NRTZP6Uw4ar","colab_type":"text"},"source":["### 2. Loading the required modules\n","\n","Python relies on loading in other modules and libraries that have special in-built functions for tasks that we want to perform. \n","\n","Keras (which is a higher-level abstraction of tensorflow) is a super easy API which has pre-programmed a lot of the dependancies and code necessary to completely build and train a neural net.\n","\n","Next to each module I've included a comment about wtf it does."]},{"cell_type":"code","metadata":{"id":"Sjfthmqnw6Hn","colab_type":"code","colab":{}},"source":["\n","import numpy as np   # Loading in numpy (a module for vector / array calculations) anc calling it \"np\"\n","np.random.seed(123)  # As the models are initiated randomly, then we set the seed on this workbook so that it isn't random and we all get the same output.\n","import tensorflow as tf # Importing our first module (as below) but we need it \n","\n","from keras.models import Sequential, load_model # Keras holds all the tools, here we're accessing its \"models\" library \n","                                                # and installing the \"Sequential\" model that allows us to stack all the layers \n","                                                # in the CNN and it takes care of all the maths and setup. load_model allows us to\n","                                                # load previously saved models.\n","\n","\n","from keras.layers import Dense, Dropout, Activation, Flatten \n","# Dense: the old fully-connected layer\n","# Dropout: randomly drops out some of the connections during each training phase (may be helpful in comp...)\n","# Activation: your choice of activation function to apply for non-linearities\n","# Flatten: transforms from high-dimension to a 1D vector\n","\n","from keras.layers import Conv2D, MaxPooling2D  # Convolution2D: finds the 2D features; MaxPooling2D reduces the dimensionality of the features\t\n","from keras.utils import np_utils # This allows us to manipulate the data a bit easier later\n","\n","from keras.callbacks import ModelCheckpoint # Allows us to store versions of the model as it goes through its training, \n","                                            # may be useful in competition time...\n","\n","\n","from keras.datasets import mnist\t# The lovely people at Keras already have the data for us ready in a nice format, so might as well use it\n","\n","\n","from matplotlib import pyplot as plt  # Some plotting "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpMxvFbqxCRJ","colab_type":"text"},"source":["### 3. Loading the data and analysing the data \n","\n","It's important we have separate test and train sets for our data so that we can comparatively measure the performance between models on unseen data.\n","\n","If we fed all the data to the NN then it may \"overfit\" ie. not account for generalisations of 7s. We'd have no way of seeing whether this was the case as we'd only be able to test it on seen data, which we know it performs well on.\n","\n","By holding some data back, we can see when the performance of the model begins to deteriorate due to this overfitting effect."]},{"cell_type":"code","metadata":{"id":"J5oiy02UxQ42","colab_type":"code","colab":{}},"source":["# Load pre-shuffled MNIST data into train and test sets\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","print(X_train.shape) # Should be: (60000, 28, 28) ie. 60,000 instances of numbers in images that are 28x28 pixels.\n","print(y_train.shape) # Should be: (60000,) ie. 60,000 classifications ie. either 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n","print(X_test.shape)  # We have 10,000 test images to try out with our model later\n","print(y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLj_QYmGxRz6","colab_type":"text"},"source":["I mean, that's cool and all, but what the hell does this stuff actually look like?"]},{"cell_type":"code","metadata":{"id":"0iCY7SmJxW3m","colab_type":"code","colab":{}},"source":["print(y_train[0]) # Plotting the correct label of the first (yes, Python starts counting from zero) image, supposedly a 5\n","plt.imshow(X_train[0], cmap = 'Greys') # Plotting the image to see what it looks like (reasonably a 5), cmap specifies the colour scheme\n","# Note the 28x28 image size on the x and y axis"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjx93S-0xxS1","colab_type":"code","colab":{}},"source":["# Can you write some code to obtain two images of 4s? (May need 2 code cells here)\n","# It would be helpful to be able to plot a small list of labels from y_train to see where they turn up...\n","\n","print(y_train[:10]) # Plotting the first 10 labels, and see there is a 4 at position 3 and 10 (which is index 2 and 9 in Python...)\n","plt.imshow(X_train[2], cmap = 'Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6cJHA8Wx4bP","colab_type":"code","colab":{}},"source":["plt.imshow(X_train[9], cmap= 'Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fsVnk7iuyLCa","colab_type":"text"},"source":["### 4. Pre-processing the data for NNs\n","\n","The image and label data aren't particularly in the format that the Keras model will want.\n","\n","NNs simply take a vector of numbers as their input and transform them to a different vector as their output. These images are 28x28 pixels, each one with a value from 0 to 255 to represent how black/white that pixel is.\n","The outputs we've got here are 0,1,2,3,4,5,6,7,8,9, which aren't actually vectors that the machine can work with.\n","\n","What the model wants is an input that's a 1D vector that's 784 pieces long (ie. 28*28), and an output that's a vector of 10 probabilities that sum to 1 (ie. the probability that it thinks it's a 0, a 1, a 2 etc.)."]},{"cell_type":"markdown","metadata":{"id":"7br9-I9Kz7UO","colab_type":"text"},"source":["\n","It'll then compare it's output probabilities to the true probabilities of the input. ie. a true 7 would be [0, 0, 0, 0, 0, 0, 0, 1, 0, 0] meaning it's 100% a 7 and it isn't anything else.\n","\n","(The machine might put out something like [0, 0, 0, 0, 0, 0.2, 0, 0.8, 0, 0] meaning it thinks the image is most likely a 7 with 80% chance, but could also be a 5 with a 20% chance).\n","\n","The difference between the output vector from the model and the true probability is measured by a loss function called categorical cross-entropy, which is some needless maths. Just bear in mind it gives us a measure of how much we need to update our model parameters to get closer to an optimal answer (hopefully)."]},{"cell_type":"code","metadata":{"id":"bYyQajPKyEXs","colab_type":"code","colab":{}},"source":["# The image data isn't quite in the format that the Keras NN will want, so we want to change it:\n","print(X_train.shape)\n","X_train = X_train.reshape(60000, 784)\n","print(X_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-l4P_aB1aOa","colab_type":"code","colab":{}},"source":["# Can you do it for the image test set?\n","X_test = X_test.reshape(X_test.shape[0], 784)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8myApT31SnO","colab_type":"text"},"source":["The pixel values in MNIST (as they are black and white) go from 0 to 255 - all the way from white, through grey, to black. \n","\n","If we use the pixel values as-is then their size and variation is so large that, when being multiplied through the weight-matrices, they could cause large errors in the output - which would cause large corrections in the backprop during training. Having these constantly large corrections may mean that the model may not converge.\n","\n","On account of this we transform the pixel data to the range [0, 1] by dividing each pixel value by the max pixel value possible (255)."]},{"cell_type":"code","metadata":{"id":"SImKNuIA1JpL","colab_type":"code","colab":{}},"source":["X_train = X_train.astype('float32')\n","X_train /= 255 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arPFfTew1cYc","colab_type":"code","colab":{}},"source":["# Same for the test set again please :) \n","\n","X_test = X_test.astype('float32')\n","X_test /= 255"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ziIb8NWf1iXH","colab_type":"text"},"source":["And now to convert the label data into the vectors we want"]},{"cell_type":"code","metadata":{"id":"x3zl5A-P1dok","colab_type":"code","colab":{}},"source":["# Convert 1-dimensional class arrays to 10-dimensional class matrices\n","print(y_train.shape)\n","Y_train = np_utils.to_categorical(y_train, 10)\n","print(Y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOJYDPHu1puO","colab_type":"code","colab":{}},"source":["# Again, do the same for the test set...\n","Y_test = np_utils.to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UZQw5Fax2MrT","colab_type":"text"},"source":["### 5. Defining a model\n","\n","This is the fun bit, as we can stack the layers like legos and Keras will pretty much take care of all the inbetween layer stuff.\n","\n","Here we call the Sequential API that allows us to stack feed-forward layers of varying sizes, with varying activation functions, without having to worry about a lot of the connections/ output to input size and luckily forgoing a lot of maths!"]},{"cell_type":"code","metadata":{"id":"GemQ50D81qXP","colab_type":"code","colab":{}},"source":["model = Sequential() # Gets us ready to build the model sequentially\n","model.add(Dense(500, input_dim=784, activation=\"relu\")) # layer that takes our 784 length vector and crushes it to 392\n","\n","# From here on in (inc the 500 above) these layer length vector choices are completely arbitrary, you can make them what you want.\n","# I've done them so there are approx the same number of params that we'll have in the CNN later.\n","model.add(Dense(300, activation=\"relu\")) # Goes 500 to 300\n","model.add(Dense(200, activation=\"relu\")) # 300 to 200\n","model.add(Dense(50, activation=\"relu\")) # 200 to 50\n","model.add(Dense(10, activation=\"relu\")) # layer that crushes a length 50 vector to a length 10 vector\n","model.add(Activation(\"softmax\")) # converts our 10 length vector to a set of probabilities that sum to 1.\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Defines our loss function, optimiser and other metrics we want measuring.\n","# At this stage the model has been initiated, but with random weights - it has yet to be trained\n","\n","print(model.summary()) # Allows us to have a high-level overview of the model!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FbVfdIfv4c-E","colab_type":"text"},"source":["You can use the block below to build your own model, we've started it for you by calling your model: \"my_model\" and calling Sequential(). \n","\n","Fill in the rest of your model, remembering to use my_model.add() as your model has a different name!"]},{"cell_type":"code","metadata":{"id":"HcHoZAob4auU","colab_type":"code","colab":{}},"source":["my_model = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WANQ4uwV4614","colab_type":"text"},"source":["### 6. Training a model\n","\n","Given the absolute headache of all that we've done previously, this bit's a doddle.\n","Keras takes care of all of the training using the model.fit() function that takes our training data and breaks it into batch sizes of 32.\n","It'll feed the 32 image vectors through, record the errors (categorical log-loss) and then make changes to the weights in the net accordingly. You can make this smaller, so that it updates errors more frequently - but then it becomes more computationally complex...\n","\n","Once all 60,000 images have gone through then that's one \"epoch\" done. However it is likely that in seeing some of the later image vectors that the NN has undone its learning about some of the earlier images, so we feed the data through for multiple epochs (here 10) so that it tries to remember all the data.\n","\n","\n","You can see the model fit function here: https://keras.io/models/model/"]},{"cell_type":"code","metadata":{"id":"wJe-nN815MPd","colab_type":"code","colab":{}},"source":["checkpointer = ModelCheckpoint('simple_NN-{epoch:02d}.hdf5', verbose = 1) # This will (temporarily) save the model to our drive after each epoch, with the epoch number \n","model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1, callbacks=[checkpointer]) # Verbose = 1 shows the progress of the model training!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GusH0995V_O","colab_type":"text"},"source":["See whether you can fit your model2 for:\n","- 12 epochs\n","- batch size of 128 images\n","- Don't use callbacks, but investigate them here: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint?version=stable\n","\n","- Then save the final model"]},{"cell_type":"code","metadata":{"id":"1CBeM4ws5W0k","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8rrjf-tJ6F5H","colab_type":"text"},"source":["### 7. Testing a model\n","\n","Again, Keras has us sorted and it's as simple as calling one simple function: evaluate.\n","\n","Here we'll be looking at: \n","- How well did our original model do after 9 epochs?\n","- How about after 10? Did we see any improvement?\n","- How about your model after 12 epochs?"]},{"cell_type":"markdown","metadata":{"id":"d0DgPQaz6PbZ","colab_type":"text"},"source":["Original model after 9 epochs: (we'll need to load model)"]},{"cell_type":"code","metadata":{"id":"Wm6s3jA-5oIr","colab_type":"code","colab":{}},"source":["epoch9_model = load_model('simple_NN-09.hdf5')\n","epoch9_score = epoch9_model.evaluate(X_test, Y_test, verbose = 1)\n","print('Test loss: ', epoch9_score[0])\n","print('Test accuracy: ', epoch9_score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ao49DAsq6eOT","colab_type":"text"},"source":["Load and test 10 epoch model:"]},{"cell_type":"code","metadata":{"id":"NUEVlO0v6ZS5","colab_type":"code","colab":{}},"source":["# Technically the model is already stored in memory as \"model\", so we don't really need\n","# to load it as something else, but it's good practice...\n","\n","epoch10_model = load_model('simple_NN-10.hdf5')\n","epoch10_score = epoch10_model.evaluate(X_test, Y_test, verbose = 1)\n","print('Test loss: ', epoch10_score[0])\n","print('Test accuracy: ', epoch10_score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OQ_U_YI6l4A","colab_type":"text"},"source":["Finally load and test your model:"]},{"cell_type":"code","metadata":{"id":"SwYfNnlo6h_y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UfKOegzp6pGX","colab_type":"text"},"source":["# Building a CNN\n","\n","The problem with having a feed-forward neural net for image classification is that the locality of the pixels is lost when compressing to a single vector.\n","\n","For instance, the immediate pixels around pixel 31 are: 2, 3, 4, 30, 32, 58, 59, 60 - which are quite some distance apart when considering they're actually next to each other. This problem will be exacerbated in larger images.\n","\n","\n","MNIST is quite a simple dataset, so even the feed-forward net does relatively well (taking us up to ~97% test accuracy).\n","We will find that CNNs, by preserving the locality of the pixels, find much better features in the images to predict from, and can take us to the 99.7% level."]},{"cell_type":"markdown","metadata":{"id":"S-WLe5GUvD85","colab_type":"text"},"source":["### 1. Reloading the data\n","\n","We already loaded the necessary modules at the beginning of this document, such as MaxPooling and Conv2D, but we will need to reload our data sets given that we changed their shape in part 1:"]},{"cell_type":"code","metadata":{"id":"a82xulemvY5c","colab_type":"code","colab":{}},"source":["# Load pre-shuffled MNIST data into train and test sets\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","print(X_train.shape) # Should be: (60000, 28, 28) ie. 60,000 instances of numbers in images that are 28x28 pixels.\n","print(y_train.shape) # Should be: (60000,) ie. 60,000 classifications ie. either 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n","print(X_test.shape)  # We have 10,000 test images to try out with our model later\n","print(y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VTGKGAm1vnGh","colab_type":"text"},"source":["And once again, it has to be reshaped. The images are already in their 28 x 28 pixel form, but now we have to specify that we're only looking at one colour (greyscale).\n","\n","Kera treats this as the number of \"channels\". So our greyscale images have one channel, but if we were to have them in full RGB colour, then Keras would have to look over 3 images of 28 x 28:\n","- One in red\n","- One in green\n","- One in blue"]},{"cell_type":"code","metadata":{"id":"Ga1cNehewIpH","colab_type":"code","colab":{}},"source":["# The image data isn't quite in the format that the Keras CNN will want, so we want to change it:\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1) # reshape it into 60,000 instances of 28 height x 28 width x 1 channel images\n","input_shape = (28, 28, 1)  # Just useful here to store what will be the eventual input shape for the keras model.\n","\n","# Can you do it for the image test set?\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QtrblWIdwTAD","colab_type":"text"},"source":["And again, convert it to [0,1]..."]},{"cell_type":"code","metadata":{"id":"2_Ho_qT_wKu3","colab_type":"code","colab":{}},"source":["X_train = X_train.astype('float32')\n","X_train /= 255 \n","\n","# Same for the test set again please :) \n","\n","X_test = X_test.astype('float32')\n","X_test /= 255"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3soHxC_Vwfia","colab_type":"text"},"source":["And finally, rename our y labels from 0,1,2,3,4,5,6,7,8,9 to our vector representations:"]},{"cell_type":"code","metadata":{"id":"TJhy0NIOwZdh","colab_type":"code","colab":{}},"source":["# Convert 1-dimensional class arrays to 10-dimensional class matrices\n","print(y_train.shape)\n","Y_train = np_utils.to_categorical(y_train, 10)\n","print(Y_train.shape)\n","\n","\n","# Again, do the same for the test set...\n","Y_test = np_utils.to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"APQvXnI8wvDo","colab_type":"text"},"source":["### 2. Defining a model\n","\n","Two key layers in building convolutional neural nets are:\n","1. Conv2D (convolutional layers)\n","\n","2. MaxPooling2D (provides robustness by extracting the important features to a lower dimensional representation).\n","\n","\n","The convolutional layers (in the case below) sweep 32 grids (filters) of dimension 3x3 over the entirety of the image. \n","As you move the box one pixel each time then each grid sweeps out it's own 26x26 pixel image. This image will look different for each filter, and each will highlight the feature in the image that it deems important.\n","\n","Then, for all of these 32 images simultaneously, a different set of 3x3 filters attempts to extract their important info.\n","Thus we end up with 32 feature extractions of 24x24 pixels.\n","\n","This is then down-sampled by max-pooling (it aggregates the data contained in these images by splitting the images into non-overlapping blocks and taking \"the most important\" number in that block, so 4 pixels may be given 1 value).\n","\n","The down-sample is then flattened out into a long vector that represents the image in terms of the learned features.\n","\n","A couple of dense layers then try to learn the interactions between the extracted features and the desired output - using a softmax activation to output 10 probabilities - one for each digit."]},{"cell_type":"code","metadata":{"id":"1WaRmiJawoXq","colab_type":"code","colab":{}},"source":["model = Sequential() # Start the legos\n","\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # Tell it to use 32 filters of size 3x3, then ReLu the output.\n","print(model.output_shape)\n","\n","model.add(Conv2D(32, (3, 3), activation='relu')) # Do the same again!\n","print(model.output_shape)\n","\n","model.add(MaxPooling2D(pool_size=(2,2))) # Down-sample in boxes of size 2x2 with no-overlap. Allows for some translation invariance in the image.\n","print(model.output_shape)\n","\n","model.add(Flatten()) # Convert to one long vector for the computer to figure out what's important.\n","print(model.output_shape)\n","\n","model.add(Dense(128, activation='relu')) # The thinking (fully-connected) layer.\n","print(model.output_shape)\n","\n","model.add(Dense(10, activation='softmax')) # The dense layer that outputs the probabilities\n","print(model.output_shape)\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Defines our loss function, optimiser and other metrics we want measuring.\n","# At this stage the model has been initiated, but with random weights - it has yet to be trained\n","\n","print(model.summary()) # Allows us to have a high-level overview of the model!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lnlk6pHhy7QQ","colab_type":"text"},"source":["### 3. Training the model\n","\n","Same as before! (Got to love Keras)."]},{"cell_type":"code","metadata":{"id":"vzlY03BvzDfZ","colab_type":"code","colab":{}},"source":["checkpointer = ModelCheckpoint('CNN-{epoch:02d}.hdf5', verbose = 1) # This will (temporarily) save the model to our drive after each epoch, with the epoch number \n","model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1, callbacks=[checkpointer]) # Verbose = 1 shows the progress of the model training!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ITBa5XUdzJC3","colab_type":"text"},"source":["### 4. Testing the model\n","\n","As the model is stored as \"model\" in memory currently, then we can just call it directly for testing, without having to load it from Drive:"]},{"cell_type":"code","metadata":{"id":"qJH3wUitzHfu","colab_type":"code","colab":{}},"source":["model_score = model.evaluate(X_test, Y_test, verbose = 1)\n","print('Test loss: ', model_score[0])\n","print('Test accuracy: ', model_score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0NhtcbhUzd8l","colab_type":"text"},"source":["Hopefully, you'll see that with the same number of parameters, that our CNN is outperforming our NN!\n","\n","Though note that this may not be the case, as the initialisation state of the weights in these models are random. \n","So even if we trained exactly the same model again from scratch, it would produce a different result as it would have a different starting point.\n","\n","Therefore we can still expect some variance in our test score."]},{"cell_type":"markdown","metadata":{"id":"UJP9S17l0Lkg","colab_type":"text"},"source":["This model, taken from https://keras.io/examples/mnist_cnn/ uses:\n","\n","- Convolutional Layer (32 filters of size 3x3, with relu)\n","- Same again, but 64 filters!\n","- The MaxPooling layer as above\n","- A dropout layer with rate 0.25 (these dropout layers reduce overfitting in the model, so should help performance)\n","- Flatten\n","- Dense(128) layer\n","- Dropout with rate 0.5\n","- Output layer of size 10, with the softmax activation\n","- The AdaDelta optimiser, with the loss as before"]},{"cell_type":"code","metadata":{"id":"29JOdW8jzjn0","colab_type":"code","colab":{}},"source":["# Start with sequential...\n","model2 = Sequential() \n","\n","model2.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=(28, 28, 1)))\n","\n","model2.add(Conv2D(64, (3, 3), activation='relu'))\n","\n","model2.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model2.add(Dropout(0.25))\n","\n","model2.add(Flatten())\n","\n","model2.add(Dense(128, activation='relu'))\n","\n","model2.add(Dropout(0.5))\n","\n","model2.add(Dense(10, activation='softmax'))\n","\n","# Compile it ...\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adadelta',\n","              metrics=['accuracy'])\n","\n","# Print summary...\n","print(model2.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bV6aiDdj0smK","colab_type":"text"},"source":["Train, but this time with 12 epochs and a batch size of 128:"]},{"cell_type":"code","metadata":{"id":"W1M5w-Kd0oG7","colab_type":"code","colab":{}},"source":["model2.fit(X_train, Y_train, batch_size=128, epochs=12, verbose=1) # Verbose = 1 shows the progress of the model training!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PKk1B0La1C2A","colab_type":"text"},"source":["And evaluate:"]},{"cell_type":"code","metadata":{"id":"GYmJgXxe1CDq","colab_type":"code","colab":{}},"source":["model2_score = model2.evaluate(X_test, Y_test, verbose = 1)\n","print('Test loss: ', model2_score[0])\n","print('Test accuracy: ', model2_score[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pk6h6BSe1SXb","colab_type":"text"},"source":["^ for me, at time of running, that's breaking the 99% accuracy marker"]},{"cell_type":"markdown","metadata":{"id":"mbLZ2Z7eC38o","colab_type":"text"},"source":["# Taking real images from my laptop\n","\n","I get it, the above is pretty boring. It's just numbers. Can I make it do something from my phone camera though?\n","\n","Step one: a single prediction on a data point we already have:"]},{"cell_type":"code","metadata":{"id":"bj5XJ4U1DnUw","colab_type":"code","colab":{}},"source":["image = X_train[100].reshape(28, 28) # turn it back into the shape the plots can handle.\n","print(Y_train[100]) # so it's supposedly a 5...\n","plt.imshow(image, cmap = 'Greys')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jk5e07igEODX","colab_type":"text"},"source":["Does the model predict it's a 5 though?"]},{"cell_type":"code","metadata":{"id":"ImiqMvaED2g-","colab_type":"code","colab":{}},"source":["input_img = X_train[100].reshape(1,28,28,1)\n","result = model2.predict(input_img) # gives a vector of probabilities\n","print(np.sum(result)) # shows they sum to 1.\n","\n","print(np.argmax(result)) # will pick the entry with the highest prob..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"04j87HliGYjU","colab_type":"text"},"source":["It's a 5!!! Impressive for such a squiggle!\n","\n","Can I now get one from my laptop though?"]},{"cell_type":"code","metadata":{"id":"SSh5Vq3lEp6T","colab_type":"code","colab":{}},"source":["# Writing a quick function to load an image, squish it to size, \n","# turn it to greyscale and resize it to 28x28 it to what we want:\n","\n","from PIL import Image # quite a nice library for this task\n","import PIL.ImageOps  # Used to turn the image into a black number\n","\n","def file_to_input(string):\n","  img  = Image.open(string) # loads image from the file\n","  width, height = img.size # get the size of the image\n","  area = (width/4, height/4, 3*width/4, 3*height/4) \n","  img = img.crop(area) # crops to the area, which happens to be the middle of the image\n","\n","  img = img.resize((28, 28)) # resize the image to 28x28\n","  img = img.convert('L') # turn to greyscale\n","  img = PIL.ImageOps.invert(img)\n","\n","  pic = np.array(img)\n","  pic = pic/255\n","  # np.place(pic, pic < 0.5, 0) # these could possibly used to sharpen the images...\n","  # np.place(pic, pic > 0.5, 1)\n","\n","  return pic"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIEzK9wpKadA","colab_type":"code","colab":{}},"source":["img1 = file_to_input('5 v1.jpg')\n","print(img1.shape)\n","plt.imshow(img1, cmap='Greys')\n","img1_reshape = img1.reshape(1,28,28,1)\n","result = model2.predict(img1_reshape)\n","print(np.argmax(result))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TOwebJ1pNSJb","colab_type":"text"},"source":["Correct!"]},{"cell_type":"code","metadata":{"id":"vIL0-SXxKeqs","colab_type":"code","colab":{}},"source":["img2 = file_to_input('5 v2.jpg')\n","print(img2.shape)\n","plt.imshow(img2, cmap='Greys')\n","img2_reshape = img2.reshape(1,28,28,1)\n","result = model2.predict(img2_reshape)\n","print(np.argmax(result))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kpm5BKaQNTzi","colab_type":"text"},"source":["Correct!"]},{"cell_type":"code","metadata":{"id":"YSQSfDGoLo-7","colab_type":"code","colab":{}},"source":["img3 = file_to_input('5 v3.jpg')\n","print(img3.shape)\n","plt.imshow(img3, cmap='Greys')\n","img3_reshape = img3.reshape(1,28,28,1)\n","result = model2.predict(img3_reshape)\n","print(np.argmax(result))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-sJjVVmKNWGb","colab_type":"text"},"source":["Finally tricked it! Now just to close out all the images we opened..."]},{"cell_type":"code","metadata":{"id":"skcpF_N2NhCa","colab_type":"code","colab":{}},"source":["plt.close('all')\n","Image.close('all')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ui9xnpHNiTo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}